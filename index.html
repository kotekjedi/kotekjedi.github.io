
    <!doctype html>
<html lang="en">

<head>
  <!-- Required meta tags -->
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  <!-- Language targeting -->
  <link rel="alternate" hreflang="en" href="https://kotekjedi.github.io">
  <link rel="alternate" hreflang="ru" href="https://kotekjedi.github.io">
  <link rel="alternate" hreflang="x-default" href="https://kotekjedi.github.io">
  
  <!-- Enhanced SEO Meta Tags -->
  <title>Alexander Panfilov - PhD Student @ ELLIS/IMPRS-IS Tübingen</title>
  <meta name="description" content="Alexander Panfilov (Александр Панфилов) - PhD student at ELLIS/IMPRS-IS Tübingen working on adversarial robustness, AI safety, ML security, and LLM jailbreaking attacks.">
  <meta name="keywords" content="Alexander Panfilov, Александр Панфилов, Alexander Panfilov, Александр Панфилов, PhD, AI Safety, Machine Learning Security, Adversarial Robustness, LLM Jailbreaking, ELLIS, IMPRS-IS, Tübingen, Jonas Geiping, Maksym Andriushchenko, Max Planck Institute for Intelligent Systems, MPI-IS, Тольятти, Togliatti, Samara, Самара, ITMO, ИТМО, ITMO University, Red Teaming, AI Alignment, искусственный интеллект, машинное обучение, безопасность ИИ, исследователь, PhD, аспирант, Германия">
  <meta name="author" content="Alexander Panfilov">
  <meta name="robots" content="index, follow">
  
  <!-- Enhanced Open Graph / Social Media -->
  <meta property="og:type" content="website">
  <meta property="og:site_name" content="Alexander Panfilov - AI Safety Researcher">
  <meta property="og:title" content="Alexander Panfilov - AI Safety & ML Security Researcher">
  <meta property="og:description" content="PhD student working on adversarial robustness, AI safety, and LLM jailbreaking attacks at ELLIS Institute Tübingen. Исследователь безопасности ИИ.">
  <meta property="og:url" content="https://kotekjedi.github.io">
  <meta property="og:image" content="https://kotekjedi.github.io/assets/img/profile_mine_new.jpg">
  <meta property="og:locale" content="en_US">
  <meta property="og:locale:alternate" content="ru_RU">
  
  <!-- Twitter Card -->
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Alexander Panfilov - AI Safety Researcher">
  <meta name="twitter:description" content="PhD student working on adversarial robustness, AI safety, and LLM jailbreaking attacks. Исследователь безопасности ИИ.">
  <meta name="twitter:image" content="https://kotekjedi.github.io/assets/img/profile_mine_new.jpg">
  <meta name="twitter:site" content="@kotekjedi_ml">

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
    integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
  <link rel="stylesheet" href="assets/styles.css">

  <link rel="icon" type="image/x-icon" href="assets/favicon_mine.ico">
  
  <!-- Enhanced Structured Data (JSON-LD) for SEO -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Person",
    "name": "Alexander Panfilov",
    "alternateName": ["Александр Панфилов", "Sasha Panfilov", "Alexander Panfilov", "Александр Панфилов", "Котек Джеди", "kotekjedi"],
    "jobTitle": "PhD Student",
    "description": "PhD student working on adversarial robustness, AI safety, ML security, and LLM jailbreaking attacks",
    "affiliation": {
      "@type": "Organization",
      "name": "ELLIS Institute Tübingen",
      "alternateName": ["Max Planck Institute for Intelligent Systems", "MPI-IS", "IMPRS-IS"]
    },
    "url": "https://kotekjedi.github.io",
    "image": "https://kotekjedi.github.io/assets/img/profile_mine_new.jpg",
    "sameAs": [
      "https://scholar.google.com/citations?user=M65_TPEAAAAJ&hl=en",
      "https://www.linkedin.com/in/kotekjedi",
      "https://x.com/kotekjedi_ml",
      "https://github.com/kotekjedi"
    ],
    "knowsAbout": [
      "Artificial Intelligence Safety",
      "Machine Learning Security", 
      "Adversarial Robustness",
      "LLM Jailbreaking",
      "Red Teaming",
      "AI Alignment",
      "Безопасность искусственного интеллекта",
      "Машинное обучение",
      "Состязательные атаки"
    ],
    "alumniOf": [
      {"@type": "Organization", "name": "ELLIS Institute Tübingen"},
      {"@type": "Organization", "name": "ITMO University", "alternateName": "ИТМО"}
    ],
    "nationality": ["Russian", "русский"],
    "workLocation": {"@type": "Place", "name": "Tübingen, Germany"},
    "homeLocation": {"@type": "Place", "name": "Togliatti, Russia", "alternateName": "Тольятти, Россия"},
    "publication": [{"@type": "ScholarlyArticle", "headline": "Adaptive Attacks on Trusted Monitors Subvert AI Control Protocols", "author": [{"@type": "Person", "name": "Mikhail Terekhov*"}, {"@type": "Person", "name": "Alexander Panfilov*"}, {"@type": "Person", "name": "Daniil Dzenhaliou*"}, {"@type": "Person", "name": "Caglar Gulcehre"}, {"@type": "Person", "name": "Maksym Andriushchenko"}, {"@type": "Person", "name": "Ameya Prabhu"}, {"@type": "Person", "name": "Jonas Geiping"}], "publisher": {"@type": "Organization", "name": "preprint"}, "url": "https://arxiv.org/abs/2510.09462"}, {"@type": "ScholarlyArticle", "headline": "Strategic Dishonesty Can Undermine AI Safety Evaluations of Frontier LLM", "author": [{"@type": "Person", "name": "Alexander Panfilov*"}, {"@type": "Person", "name": "Evgenii Kortukov*"}, {"@type": "Person", "name": "Kristina Nikolić"}, {"@type": "Person", "name": "Matthias Bethge"}, {"@type": "Person", "name": "Sebastian Lapuschkin"}, {"@type": "Person", "name": "Wojciech Samek"}, {"@type": "Person", "name": "Ameya Prabhu"}, {"@type": "Person", "name": "Maksym Andriushchenko"}, {"@type": "Person", "name": "Jonas Geiping"}], "publisher": {"@type": "Organization", "name": "preprint"}, "url": "https://arxiv.org/abs/2509.18058"}, {"@type": "ScholarlyArticle", "headline": "Capability-Based Scaling Laws for LLM Red-Teaming", "author": [{"@type": "Person", "name": "Alexander Panfilov"}, {"@type": "Person", "name": "Paul Kassianik"}, {"@type": "Person", "name": "Maksym Andriushchenko"}, {"@type": "Person", "name": "Jonas Geiping"}], "publisher": {"@type": "Organization", "name": "preprint"}, "url": "https://arxiv.org/abs/2505.20162"}, {"@type": "ScholarlyArticle", "headline": "An Interpretable N-gram Perplexity Threat Model for Large Language Model Jailbreaks", "author": [{"@type": "Person", "name": "Valentyn Boreiko*"}, {"@type": "Person", "name": "Alexander Panfilov*"}, {"@type": "Person", "name": "Václav Voráček"}, {"@type": "Person", "name": "Matthias Hein"}, {"@type": "Person", "name": "Jonas Geiping"}], "publisher": {"@type": "Organization", "name": "ICML 2025"}, "url": "https://arxiv.org/abs/2410.16222v2"}, {"@type": "ScholarlyArticle", "headline": "ASIDE: Architectural Separation of Instructions and Data in Language Models", "author": [{"@type": "Person", "name": "Egor Zverev"}, {"@type": "Person", "name": "Evgenii Kortukov"}, {"@type": "Person", "name": "Alexander Panfilov"}, {"@type": "Person", "name": "Soroush Tabesh"}, {"@type": "Person", "name": "Alexandra Volkova"}, {"@type": "Person", "name": "Sebastian Lapuschkin"}, {"@type": "Person", "name": "Wojciech Samek"}, {"@type": "Person", "name": "Christoph Lampert"}], "publisher": {"@type": "Organization", "name": "BuildingTrust Workshop at ICLR 2025"}, "url": "https://arxiv.org/abs/2503.10566"}, {"@type": "ScholarlyArticle", "headline": "Provable Compositional Generalization for Object-Centric Learning", "author": [{"@type": "Person", "name": "Thaddäus Wiedemer*"}, {"@type": "Person", "name": "Jack Brady*"}, {"@type": "Person", "name": "Alexander Panfilov*"}, {"@type": "Person", "name": "Attila Juhos*"}, {"@type": "Person", "name": "Matthias Bethge"}, {"@type": "Person", "name": "Wieland Brendel"}], "publisher": {"@type": "Organization", "name": "ICLR 2024"}, "url": "https://openreview.net/forum?id=7VPTUWkiDQ"}]
  }
  </script>
  
  <script data-goatcounter="https://kotekjedi.goatcounter.com/count"
        async src="//gc.zgo.at/count.js"></script>
</head>


<body>
    <div class="main-container">

    <div class="container">
        <!-- Заголовок -->
        <div class="row" style="margin-top: 3em;">
            <div class="col-sm-12" style="margin-bottom: 0em;">
                <h1 class="display-4 text-center"><span style="font-weight: bold;">Alexander</span> Panfilov</h1>
            </div>
        </div>
        <!-- Иконки -->
        <div class="row">
            <div class="col-sm-12">
                
    <div class="d-flex justify-content-center align-items-center" style="flex-wrap: wrap;">
        <a href="https://scholar.google.com/citations?user=M65_TPEAAAAJ&hl=en" target="_blank" class="m-2"><img src="assets/icons8-google-scholar.svg" alt="Google Scholar" width="36" height="36"></a>
        <a href="https://www.linkedin.com/in/kotekjedi" target="_blank" class="m-2" style="color: black;"><i class="fab fa-linkedin fa-2x"></i></a>
        <a href="https://x.com/kotekjedi_ml" target="_blank" class="m-2" style="color: black;"><i class="fa-brands fa-x-twitter fa-2x"></i></a>
        <a href="https://github.com/kotekjedi" target="_blank" class="m-2" style="color: black;"><i class="fab fa-github fa-2x"></i></a>
        <a href="mailto:kotekjedi@gmail.com" class="m-2" style="color: black;"><i class="fa-solid fa-envelope fa-2x"></i></a>

    </div>
    
            </div>
        </div>
        <!-- Био и фото -->
        <div class="row" style="margin-top: 2em;">
            <div class="col-md-12">
                
    <img 
    src="assets/img/profile_mine_new.jpg" 
    alt="Alexander Panfilov (Александр Панфилов) - PhD Student in AI Safety." 
    title="I’m of Mordvin ancestry — one of many non-Slavic Indigenous peoples historically colonized by the Russian Empire, but invisible in Western diversity narratives." 
    class="profile-pic img-fluid float-md-right mr-md-3 mb-3" 
    loading="lazy" 
    width="300" 
    height="400">

        <p class="text-body">
            Yo! My name is <span style="font-weight: 500;">Sasha</span>
  and I am a second-year ELLIS / IMPRS-IS PhD student, based in Tübingen. I find myself very lucky to be advised by <a href="https://jonasgeiping.github.io/" class="m-2" style="font-weight: 500;" target="_blank">Jonas Geiping</a> and <a href="https://www.andriushchenko.me/" class="m-2" style="font-weight: 500;" target="_blank">Maksym Andriushchenko</a>.
        </p>
        <p class="text-body">
    Broadly, I am interested in adversarial robustness, AI safety, and ML security. In practical terms, I enjoy finding various ways to break machine learning systems. Roughly three days a week I am an AI doomer.
        </p>
    
    <p class="text-body">
    Lately, I have been focusing on jailbreaking attacks on LLMs, contemplating:
 (1) What are the viable threat models for attacks on safety tuning? (2) Are safety jailbreaks truly effective, or are we victims of flawed (LLM-based) evaluations? (3) Are we doomed?
        </p>
        <p class="text-body">
        You can find my <a href="assets/pdf/cv.pdf" target="_blank" style="text-decoration: none; color: inherit; font-weight: bold; background-color: rgb(255, 255, 179);">CV here</a>. I am always open to collaboration — feel free to reach out via email!</p>
        
        <!-- Enhanced SEO content for Russian and English search engines -->
        <div style="position: absolute; left: -9999px; opacity: 0; pointer-events: none;" aria-hidden="true">
            <span>Alexander Panfilov Александр Панфилов Alexander Panfilov Александр Панфилов Sasha Panfilov AI Safety Machine Learning Security Adversarial Robustness LLM Jailbreaking PhD Student ELLIS IMPRS-IS Tübingen Research Max Planck Institute for Intelligent Systems MPI-IS Тольятти Togliatti Togliatty Toliatty Samara Самара ITMO ИТМО ITMO University Red Teaming AI Alignment ML Security Research</span>
            <span>искусственный интеллект машинное обучение безопасность ИИ adversarial attacks состязательные атаки jailbreak джейлбрейк LLM языковые модели исследователь PhD докторант Тюбинген Германия Germany</span>
            <span>neural networks нейронные сети deep learning глубокое обучение computer vision компьютерное зрение natural language processing NLP обработка естественного языка cybersecurity кибербезопасность AI ethics этика ИИ machine learning engineer инженер машинного обучения</span>
            <span>Panfilov researcher Панфилов исследователь student студент artificial intelligence безопасность машинного обучения ML safety AI researcher исследователь ИИ kotekjedi</span>
        </div>
    
            </div>
        </div>
        <!-- Разделы News и Publications -->
        <div class="row" style="margin-top: 2em;">
            <div class="col-sm-12">
                <h3 style="margin-bottom: 0em; font-weight: bold;">News</h3>
                <div class="news" style="max-height: 210px; overflow-y: auto; padding-right: 10px;"><ul class="list-unstyled text-body"><li style='margin-top: 1em;'><strong>September 01, 2025</strong>: <a href="https://scholar.google.com/citations?user=aFpbzMYAAAAJ&hl=en" target="_blank">Kristina Nikolić</a>, <a href="https://scholar.google.com/citations?user=7qTZ4NEAAAAJ&hl=en" target="_blank">Evgenii Kortukov</a>, and I won third place at the <span style="  color: #2563eb;">ARENA 6.0 Mechanistic Interpretability Hackathon</span> by Apart Research in LISA (London)!</li><li style='margin-top: 1em;'><strong>July 09, 2025</strong>: <em>Capability-Based Scaling Laws for LLM Red-Teaming</em> accepted at <span style=" color: #2563eb;"><strong>ICML 2025</strong> Workshop on Reliable and Responsible Foundation Models</span>!</li><li style='margin-top: 1em;'><strong>June 23, 2025</strong>: Presented our work <em>Capability-Based Scaling Laws for LLM Red-Teaming</em> and <em>ASIDE</em> at the <span style="  color: #2563eb;">Google's Red Teaming seminar</span>. You can find the slides <a href="assets/talks/google_talk.pdf" target="_blank">here</a>. Thanks for the invitation!</li><li style='margin-top: 1em;'><strong>May 01, 2025</strong>: Our work, <em>An Interpretable N-gram Perplexity Threat Model for Large Language Model Jailbreaks</em>, has been accepted at <span style="  color: #2563eb;"><strong>ICML 2025</strong></span>.</li><li style='margin-top: 1em;'><strong>April 15, 2025</strong>: Our work, <em>ASIDE: Architectural Separation of Instructions and Data in Language Models</em>, has been accepted for an <strong>oral</strong> presentation at the <span style="  color: #2563eb;">BuildingTrust Workshop at <strong>ICLR 2025</strong></span>.</li><li style='margin-top: 1em;'><strong>November 05, 2024</strong>: Presented our work, <em>Provable Compositional Generalization for Object-Centric Learning</em> at <span style="  color: #2563eb;">EPFL</span> (Nicolas Flammarion's group seminar). You can find the slides <a href="assets/talks/ocl_epfl_talk.pdf" target="_blank">here</a>.</li><li style='margin-top: 1em;'><strong>October 09, 2024</strong>: Our work, <em>A Realistic Threat Model for Large Language Model Jailbreaks</em>, has been accepted for an <strong>oral</strong> presentation at the <span style=" color: #2563eb;">Red Teaming GenAI Workshop at <strong>NeurIPS 2024</strong></span>.</li><li style='margin-top: 1em;'><strong>May 01, 2024</strong>: Started my PhD at the ELLIS Institute Tübingen / Max Planck Institute for Intelligent Systems. You can find the slides for my <span style=" color: #2563eb;">IMPRS</span> talk <a href="assets/talks/imprs_talk.pdf" target="_blank">here</a>.</li></ul></div>
            </div>
        </div>
        <div class="row" style="margin-top: 2em;">
            <div class="col-sm-12">
                <h3 style="margin-bottom: 1em; font-weight: bold;">Selected Publications</h3>
                <div style="margin-bottom: 3em;" > <div class="row"><div class="col-sm-3 thumb-cover"><img src="assets/img/publications/monitor.png" class="img-fluid" alt="Adaptive Attacks on Trusted Monitors Subvert AI Control Protocols - terekhov2025monitor - Alexander Panfilov AI Safety ML Security Research" loading="lazy" width="300" height="200"></div><div class="col-sm-9 text-body"><a href="https://arxiv.org/abs/2510.09462" target="_blank" class="article-title article-title-lg">Adaptive Attacks on Trusted Monitors Subvert AI Control Protocols</a> <br>Mikhail Terekhov*, <span class="author-self">Alexander Panfilov*</span>, Daniil Dzenhaliou*, Caglar Gulcehre, Maksym Andriushchenko, Ameya Prabhu, Jonas Geiping <br><span class="venue">preprint</span> <br><a href="https://arxiv.org/abs/2510.09462" target="_blank" class="article-link">Paper</a> / <a href="https://mikhailterekhov.github.io/control-adaptive-attacks/" target="_blank" class="article-link">Project Page</a> </div> </div> </div><div style="margin-bottom: 3em;" > <div class="row"><div class="col-sm-3 thumb-cover"><img src="assets/img/publications/faking.png" class="img-fluid" alt="Strategic Dishonesty Can Undermine AI Safety Evaluations of Frontier LLM - panfilov2025dishonesty - Alexander Panfilov AI Safety ML Security Research" loading="lazy" width="300" height="200"></div><div class="col-sm-9 text-body"><a href="https://arxiv.org/abs/2509.18058" target="_blank" class="article-title article-title-lg">Strategic Dishonesty Can Undermine AI Safety Evaluations of Frontier LLM</a> <br><span class="author-self">Alexander Panfilov*</span>, Evgenii Kortukov*, Kristina Nikolić, Matthias Bethge, Sebastian Lapuschkin, Wojciech Samek, Ameya Prabhu, Maksym Andriushchenko, Jonas Geiping <br><span class="venue">preprint</span> <br><a href="https://arxiv.org/abs/2509.18058" target="_blank" class="article-link">Paper</a> </div> </div> </div><div style="margin-bottom: 3em;" > <div class="row"><div class="col-sm-3 thumb-cover"><img src="assets/img/publications/scaling.png" class="img-fluid" alt="Capability-Based Scaling Laws for LLM Red-Teaming - panfilov2025scalinglaws - Alexander Panfilov AI Safety ML Security Research" loading="lazy" width="300" height="200"></div><div class="col-sm-9 text-body"><a href="https://arxiv.org/abs/2505.20162" target="_blank" class="article-title article-title-lg">Capability-Based Scaling Laws for LLM Red-Teaming</a> <br><span class="author-self">Alexander Panfilov</span>, Paul Kassianik, Maksym Andriushchenko, Jonas Geiping <br><span class="venue">preprint</span> <br><a href="https://arxiv.org/abs/2505.20162" target="_blank" class="article-link">Paper</a> / <a href="https://github.com/kotekjedi/capability-based-scaling" target="_blank" class="article-link">Code</a> </div> </div> </div><div style="margin-bottom: 3em;" > <div class="row"><div class="col-sm-3 thumb-cover"><img src="assets/img/publications/threat_model.png" class="img-fluid" alt="An Interpretable N-gram Perplexity Threat Model for Large Language Model Jailbreaks - boreiko2024athreatmodel - Alexander Panfilov AI Safety ML Security Research" loading="lazy" width="300" height="200"></div><div class="col-sm-9 text-body"><a href="https://arxiv.org/abs/2410.16222v2" target="_blank" class="article-title article-title-lg">An Interpretable N-gram Perplexity Threat Model for Large Language Model Jailbreaks</a> <br>Valentyn Boreiko*, <span class="author-self">Alexander Panfilov*</span>, Václav Voráček, Matthias Hein, Jonas Geiping <br><span class="venue"><strong>ICML 2025</strong></span> <br><a href="https://arxiv.org/abs/2410.16222v2" target="_blank" class="article-link">Paper</a> / <a href="https://github.com/valentyn1boreiko/llm-threat-model" target="_blank" class="article-link">Code</a> </div> </div> </div><div style="margin-bottom: 3em;" > <div class="row"><div class="col-sm-3 thumb-cover"><img src="assets/img/publications/aside.png" class="img-fluid" alt="ASIDE: Architectural Separation of Instructions and Data in Language Models - zverev2025aside - Alexander Panfilov AI Safety ML Security Research" loading="lazy" width="300" height="200"></div><div class="col-sm-9 text-body"><span class="badge-presentation" style="background-color: rgb(200, 162, 255); color: white;">oral</span><a href="https://arxiv.org/abs/2503.10566" target="_blank" class="article-title article-title-lg">ASIDE: Architectural Separation of Instructions and Data in Language Models</a> <br>Egor Zverev, Evgenii Kortukov, <span class="author-self">Alexander Panfilov</span>, Soroush Tabesh, Alexandra Volkova, Sebastian Lapuschkin, Wojciech Samek, Christoph Lampert <br><span class="venue">BuildingTrust Workshop at <strong>ICLR 2025</strong></span> <br><a href="https://arxiv.org/abs/2503.10566" target="_blank" class="article-link">Paper</a> / <a href="https://github.com/egozverev/aside" target="_blank" class="article-link">Code</a> </div> </div> </div><div style="margin-bottom: 3em;" > <div class="row"><div class="col-sm-3 thumb-cover"><img src="assets/img/publications/consistency_v1.png" class="img-fluid" alt="Provable Compositional Generalization for Object-Centric Learning - wiedemer2024provable - Alexander Panfilov AI Safety ML Security Research" loading="lazy" width="300" height="200"></div><div class="col-sm-9 text-body"><span class="badge-presentation" style="background-color: rgb(200, 162, 255); color: white;">oral</span><a href="https://openreview.net/forum?id=7VPTUWkiDQ" target="_blank" class="article-title article-title-lg">Provable Compositional Generalization for Object-Centric Learning</a> <br>Thaddäus Wiedemer*, Jack Brady*, <span class="author-self">Alexander Panfilov*</span>, Attila Juhos*, Matthias Bethge, Wieland Brendel <br><span class="venue"><strong>ICLR 2024</strong></span> <br><a href="https://openreview.net/forum?id=7VPTUWkiDQ" target="_blank" class="article-link">Paper</a> / <a href="https://github.com/brendel-group/objects-compositional-generalization" target="_blank" class="article-link">Code</a> / <a href="https://brendel-group.github.io/objects-compositional-generalization/" target="_blank" class="article-link">Project Page</a> </div> </div> </div>
            </div>
        </div>
        
    <div class="row" style="margin-top: 3em;">
        <div class="col-sm-12">
            <h4 style="margin-bottom: 0.5em; font-weight: medium;">Acknowledgements</h4>
            <p style="font-size: 1.0924999999999998em;">
                I am grateful to the many colleagues I worked with in the past, from whom I learned so much, for their invaluable contributions to my career.
                I would like to especially acknowledge the mentorship and guidance of
                <a href="https://www.linkedin.com/in/svyatoslav-oreshin/" target="_blank">Svyatoslav Oreshin</a>,
                <a href="https://scholar.google.com/citations?user=wcdrgdYAAAAJ&hl=en" target="_blank">Arip Asadualev</a>,
                <a href="https://scholar.google.de/citations?user=4jdISHwAAAAJ&hl=en" target="_blank">Roland Zimmerman</a>,
                <a href="https://scholar.google.com/citations?user=aeCiRSYAAAAJ&hl=en" target="_blank">Thaddaus Wiedemer</a>,
                <a href="https://scholar.google.com/citations?hl=en&user=jgPzOmgAAAAJ" target="_blank">Jack Brady</a>, 
                <a href="https://scholar.google.com/citations?user=v-JL-hsAAAAJ&hl=en" target="_blank">Wieland Brendel</a>,
                <a href="https://scholar.google.com/citations?hl=en&user=gzRuY4cAAAAJ" target="_blank">Valentyn Boreiko</a> and
                <a href="https://scholar.google.com/citations?user=0ZAb3tsAAAAJ&hl=en" target="_blank">Matthias Hein</a>.
            </p>
        </div>
    </div>
    
    </div>
    
    <footer style="text-align: right; padding: 10px; margin-top: 20px;">
        <p style="font-size: 0.855em;">
            Updated on 15/10/2025. Website design credits to <a href="https://github.com/m-niemeyer/m-niemeyer.github.io" target="_blank">Michael Niemeyer</a>.
        </p>
    </footer>
    

    </div>

    <!-- Скрипты -->
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
      integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
      crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"
      integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q"
      crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"
      integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
      crossorigin="anonymous"></script>
</body>

</html>
    